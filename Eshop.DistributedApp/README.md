![Aspire Resources Dashboard-TableView ](image-2.png)

![Aspire Resources - Graph view](image-3.png)


![Get Request](image.png)

![alt text](image-1.png)

![Redis Cache View](image-4.png)

![Pg Admin Screen](image-5.png)

![CatalogApi-Endpoints](image-6.png)

![BasketApi-Endpoints](image-7.png)

![Keycloak Token](image-8.png)

![Request Send with Authorization Token](image-11.png)
![alt text](image-10.png)

![alt text](image-9.png)

- Running with LLM
![With LLM](image-12.png)

![Llama calling endpoints](image-14.png)

![Call Ollama Endpoint](image-13.png)

![LLM response](image-15.png)

![Call from WebApp](image-16.png)

- Adding the LLM embedding Model

![Added Ollama-all-minilm](image-17.png)

![Resources Graph view](image-18.png)

![Keyword Search](image-19.png)

![Semantic Search](image-20.png)

![Semantic Search Example 2](image-21.png)

![Semantic Search Example 3](image-22.png)

![alt text](image-23.png)

![UI Search](image-24.png)

![Keyword Search from UI](image-25.png)

![Traces](image-26.png)

![Full service List](image-27.png)